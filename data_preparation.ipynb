{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79920fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.data_extraction_pipeline import deduplicate_embeddings_efficient\n",
    "from src.data_preparation_utils import (\n",
    "    get_files,\n",
    "    load_parts,\n",
    "    create_df,\n",
    "    process_and_save_batches,\n",
    "    get_remove_indices_per_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5dcc44",
   "metadata": {},
   "source": [
    "# Loading embeddings and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c59fba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_files, embeddings_stats_df = get_files(\"embeddings\")\n",
    "labels_files, labels_stats_df = get_files(\"labels\")\n",
    "images_files, images_stats_df = get_files(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "054c20b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_parts(labels_files, \"labels\", labels_stats_df)\n",
    "embeddings = load_parts(embeddings_files, \"embeddings\", embeddings_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00d2044a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>file_name</th>\n",
       "      <th>size</th>\n",
       "      <th>part</th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/pawelp/Desktop/education/pw/deep/data_p...</td>\n",
       "      <td>initial_set_part_0_labels.npz</td>\n",
       "      <td>228 Bytes</td>\n",
       "      <td>labels</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/pawelp/Desktop/education/pw/deep/data_p...</td>\n",
       "      <td>initial_set_part_0_embeddings.npz</td>\n",
       "      <td>353.3 kB</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>52</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  \\\n",
       "0  /Users/pawelp/Desktop/education/pw/deep/data_p...   \n",
       "1  /Users/pawelp/Desktop/education/pw/deep/data_p...   \n",
       "\n",
       "                           file_name       size        part  rows  cols  \n",
       "0      initial_set_part_0_labels.npz  228 Bytes      labels    52     1  \n",
       "1  initial_set_part_0_embeddings.npz   353.3 kB  embeddings    52  2048  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_rows = labels.shape[0]\n",
    "\n",
    "pd.concat([labels_stats_df, embeddings_stats_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "206af636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>file_name</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/pawelp/Desktop/education/pw/deep/data_p...</td>\n",
       "      <td>initial_set_part_0_images.npz</td>\n",
       "      <td>7.1 MB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  \\\n",
       "0  /Users/pawelp/Desktop/education/pw/deep/data_p...   \n",
       "\n",
       "                       file_name    size  \n",
       "0  initial_set_part_0_images.npz  7.1 MB  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_stats_df[[\"file_path\", \"file_name\", \"size\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188609b8",
   "metadata": {},
   "source": [
    "# Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc0ef115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rows: 52, Deduplicated rows: 52 (0.00% reduction, 0 rows removed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_indices = deduplicate_embeddings_efficient(embeddings)\n",
    "deduplicated_rows = len(unique_indices)\n",
    "\n",
    "removed = initial_rows - deduplicated_rows\n",
    "reduction = removed / initial_rows\n",
    "print(\n",
    "    f\"Initial rows: {initial_rows}, Deduplicated rows: {deduplicated_rows} \"\n",
    "    f\"({reduction:.2%} reduction, {removed} rows removed)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c12b9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduplicated_mask = np.zeros(initial_rows, dtype=bool)\n",
    "deduplicated_mask[unique_indices] = True\n",
    "\n",
    "deduplicated_embeddings = embeddings[deduplicated_mask]\n",
    "deduplicated_labels = labels[deduplicated_mask]\n",
    "\n",
    "del embeddings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a86ea7d",
   "metadata": {},
   "source": [
    "# Tackling imbalanced distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11be8055",
   "metadata": {},
   "source": [
    "Tackle imbalanced distribution problem by undersampling majority class based on information stored in their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86d63263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of labels in the deduplicated dataset: [21 31]\n"
     ]
    }
   ],
   "source": [
    "distribution = np.unique(deduplicated_labels, return_counts=True)[1].astype(np.uint32)\n",
    "\n",
    "print(f\"Distribution of labels in the deduplicated dataset: {distribution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d139e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced embeddings size: 38 components (90.22% variance explained, original size: 2048 - 98.14% reduction)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=0.9, random_state=42)\n",
    "pca_embeddings = pca.fit_transform(deduplicated_embeddings)\n",
    "\n",
    "n_components = pca_embeddings.shape[1]\n",
    "original_components = deduplicated_embeddings.shape[1]\n",
    "variance_explained = pca.explained_variance_ratio_.sum()\n",
    "reduction = (original_components - n_components) / original_components\n",
    "print(\n",
    "    f\"Reduced embeddings size: {n_components} components \"\n",
    "    f\"({variance_explained:.2%} variance explained, original size: {original_components} - {reduction:.2%} reduction)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3e417ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of labels in the final dataset: [21]\n"
     ]
    }
   ],
   "source": [
    "enn = EditedNearestNeighbours(n_neighbors=15, n_jobs=-1)\n",
    "\n",
    "_ = enn.fit_resample(pca_embeddings, deduplicated_labels)\n",
    "\n",
    "_labels = deduplicated_labels[enn.sample_indices_]\n",
    "final_distribution = np.unique(_labels, return_counts=True)[1]\n",
    "print(f\"Distribution of labels in the final dataset: {final_distribution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9bb90ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before resampling: 52, after: 21 (59.62% reduction, 31 rows removed)\n"
     ]
    }
   ],
   "source": [
    "mask_enn = np.zeros(len(deduplicated_labels), dtype=bool)\n",
    "mask_enn[enn.sample_indices_] = True\n",
    "\n",
    "num_before = len(deduplicated_labels)\n",
    "num_after = np.sum(mask_enn)\n",
    "removed = num_before - num_after\n",
    "print(\n",
    "    f\"Rows before resampling: {num_before}, after: {num_after} \"\n",
    "    f\"({removed / num_before:.2%} reduction, {removed} rows removed)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec9ae6",
   "metadata": {},
   "source": [
    "# Remove entries in final data, split into sets and save in optimized format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "210e7678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of rows: 52, after: 21 (59.62% reduction, 31 rows removed)\n"
     ]
    }
   ],
   "source": [
    "final_mask = np.zeros(initial_rows, dtype=bool)\n",
    "_tmp = final_mask[deduplicated_mask]\n",
    "_tmp[mask_enn] = True\n",
    "final_mask[deduplicated_mask] = _tmp\n",
    "\n",
    "removed = initial_rows - np.sum(final_mask)\n",
    "print(\n",
    "    f\"Initial number of rows: {initial_rows}, after: {np.sum(final_mask)} \"\n",
    "    f\"({removed / num_before:.2%} reduction, {removed} rows removed)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b352db7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train set size: 16,\n",
      "validation set size: 2,\n",
      "test set size: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_labels = labels[final_mask]\n",
    "\n",
    "indices = np.arange(len(final_labels))\n",
    "train_idx, temp_idx, train_labels, temp_labels = train_test_split(\n",
    "    indices, final_labels, test_size=0.2, stratify=final_labels, random_state=42\n",
    ")\n",
    "val_idx, test_idx, val_labels, test_labels = train_test_split(\n",
    "    temp_idx, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "train_mask = np.zeros(len(final_labels), dtype=bool)\n",
    "train_mask[train_idx] = True\n",
    "val_mask = np.zeros(len(final_labels), dtype=bool)\n",
    "val_mask[val_idx] = True\n",
    "test_mask = np.zeros(len(final_labels), dtype=bool)\n",
    "test_mask[test_idx] = True\n",
    "\n",
    "final_train_mask = np.zeros(initial_rows, dtype=bool)\n",
    "_tmp = final_train_mask[final_mask]\n",
    "_tmp[train_mask] = True\n",
    "final_train_mask[final_mask] = _tmp\n",
    "final_val_mask = np.zeros(initial_rows, dtype=bool)\n",
    "_tmp = final_val_mask[final_mask]\n",
    "_tmp[val_mask] = True\n",
    "final_val_mask[final_mask] = _tmp\n",
    "final_test_mask = np.zeros(initial_rows, dtype=bool)\n",
    "_tmp = final_test_mask[final_mask]\n",
    "_tmp[test_mask] = True\n",
    "final_test_mask[final_mask] = _tmp\n",
    "\n",
    "print(\n",
    "    f\"Final train set size: {np.sum(final_train_mask)},\\n\"\n",
    "    f\"validation set size: {np.sum(final_val_mask)},\\n\"\n",
    "    f\"test set size: {np.sum(final_test_mask)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24cc6610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>total_removed</th>\n",
       "      <th>deduplicated</th>\n",
       "      <th>undersampled</th>\n",
       "      <th>training</th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/pawelp/Desktop/education/pw/deep/data_p...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  total_removed  \\\n",
       "0  /Users/pawelp/Desktop/education/pw/deep/data_p...             30   \n",
       "\n",
       "   deduplicated  undersampled  training  validation  test  \n",
       "0             0            30        48          34    35  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_indices_to_remove_per_file = get_remove_indices_per_file(\n",
    "    final_mask, labels_stats_df\n",
    ")\n",
    "duplicates_indices_to_remove_per_file = get_remove_indices_per_file(\n",
    "    deduplicated_mask, labels_stats_df\n",
    ")\n",
    "undersampled_indices_to_remove_per_file = get_remove_indices_per_file(\n",
    "    mask_enn, labels_stats_df\n",
    ")\n",
    "training_indices_to_remove_per_file = get_remove_indices_per_file(\n",
    "    train_mask, labels_stats_df\n",
    ")\n",
    "validation_indices_to_remove_per_file = get_remove_indices_per_file(\n",
    "    val_mask, labels_stats_df\n",
    ")\n",
    "test_indices_to_remove_per_file = get_remove_indices_per_file(\n",
    "    test_mask, labels_stats_df\n",
    ")\n",
    "\n",
    "final_stats_df = create_df(final_indices_to_remove_per_file)\n",
    "final_stats_df[\"deduplicated\"] = create_df(duplicates_indices_to_remove_per_file)[\n",
    "    \"total_removed\"\n",
    "]\n",
    "final_stats_df[\"undersampled\"] = create_df(undersampled_indices_to_remove_per_file)[\n",
    "    \"total_removed\"\n",
    "]\n",
    "final_stats_df[\"training\"] = (\n",
    "    initial_rows - create_df(training_indices_to_remove_per_file)[\"total_removed\"]\n",
    ")\n",
    "final_stats_df[\"validation\"] = (\n",
    "    initial_rows - create_df(validation_indices_to_remove_per_file)[\"total_removed\"]\n",
    ")\n",
    "final_stats_df[\"test\"] = (\n",
    "    initial_rows - create_df(test_indices_to_remove_per_file)[\"total_removed\"]\n",
    ")\n",
    "final_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b631ae1f",
   "metadata": {},
   "source": [
    "# Save "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c091344",
   "metadata": {},
   "source": [
    "Finally only 80k for training, 10k for validation and 10k for test will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9892ea7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e7e83448cc466d8b736e67b6bd6f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing files:   0%|          | 0/1 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:59:43 - src.data_preparation_utils - INFO - Processing and saving batches of images and labels  (Elapsed time: 1.21 s)\n"
     ]
    }
   ],
   "source": [
    "process_and_save_batches(\n",
    "    training_indices_to_remove_per_file,\n",
    "    validation_indices_to_remove_per_file,\n",
    "    test_indices_to_remove_per_file,\n",
    "    labels_files,\n",
    "    images_files,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
