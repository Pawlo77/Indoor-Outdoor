{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3817ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Version: 12.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from transformers import SiglipForImageClassification, TrainingArguments, Trainer, AutoImageProcessor, EarlyStoppingCallback\n",
    "\n",
    "from src.transformers import train_transforms, val_transforms, test_transforms\n",
    "from src.callbacks import CHECKPOINT_DIR\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f8f765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SiglipForImageClassification were not initialized from the model checkpoint at google/siglip2-base-patch16-224 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "SiglipForImageClassification                            [1, 2]                    --\n",
       "├─SiglipVisionTransformer: 1-1                          [1, 768]                  --\n",
       "│    └─SiglipVisionEmbeddings: 2-1                      [1, 196, 768]             --\n",
       "│    │    └─Conv2d: 3-1                                 [1, 768, 14, 14]          590,592\n",
       "│    │    └─Embedding: 3-2                              [1, 196, 768]             150,528\n",
       "│    └─SiglipEncoder: 2-2                               [1, 196, 768]             --\n",
       "│    │    └─ModuleList: 3-3                             --                        85,054,464\n",
       "│    └─LayerNorm: 2-3                                   [1, 196, 768]             1,536\n",
       "│    └─SiglipMultiheadAttentionPoolingHead: 2-4         [1, 768]                  768\n",
       "│    │    └─MultiheadAttention: 3-4                     [1, 1, 768]               2,362,368\n",
       "│    │    └─LayerNorm: 3-5                              [1, 1, 768]               1,536\n",
       "│    │    └─SiglipMLP: 3-6                              [1, 1, 768]               4,722,432\n",
       "├─Linear: 1-2                                           [1, 2]                    1,538\n",
       "=========================================================================================================\n",
       "Total params: 92,885,762\n",
       "Trainable params: 92,885,762\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 205.69\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 162.61\n",
       "Params size (MB): 362.09\n",
       "Estimated Total Size (MB): 525.30\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = \"google/siglip2-base-patch16-224\"\n",
    "\n",
    "model = SiglipForImageClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=2,\n",
    ")\n",
    "processor = AutoImageProcessor.from_pretrained(checkpoint, use_fast=True)\n",
    "\n",
    "summary(model, input_size=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a1b0679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions, axis=-1)\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    return {\"pixel_values\": torch.stack(images), \"labels\": torch.tensor(labels)}\n",
    "\n",
    "def evaluate_model(trainer, limit=None):\n",
    "    test_ds = ImageFolder(os.path.join(\"datasets\", \"rest_test\"), transform=test_transforms)\n",
    "    if limit is not None:\n",
    "        test_ds = Subset(test_ds, range(limit))\n",
    "    score_rest = trainer.evaluate(test_ds)\n",
    "\n",
    "    test_ds = ImageFolder(os.path.join(\"datasets\", \"wit_test\"), transform=test_transforms)\n",
    "    if limit is not None:\n",
    "        test_ds = Subset(test_ds, range(limit))\n",
    "    score_wit = trainer.evaluate(test_ds)\n",
    "\n",
    "    return pd.DataFrame([score_rest, score_wit], index=[\"rest\", \"wit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1588c53",
   "metadata": {},
   "source": [
    "# Other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30784218",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DIR = os.path.join(\n",
    "    CHECKPOINT_DIR, \"siglip2\", \"other\"\n",
    ")\n",
    "os.makedirs(TARGET_DIR, exist_ok=True)\n",
    "\n",
    "train_ds = ImageFolder(os.path.join(\"datasets\", \"rest_train\"), transform=train_transforms)\n",
    "# train_ds = Subset(train_ds, range(100))\n",
    "\n",
    "val_ds = ImageFolder(os.path.join(\"datasets\", \"rest_val\"), transform=val_transforms)\n",
    "# val_ds = Subset(val_ds, range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "768077ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20682' max='1149000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  20682/1149000 9:17:42 < 507:09:12, 0.62 it/s, Epoch 18/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.058582</td>\n",
       "      <td>0.987593</td>\n",
       "      <td>0.987727</td>\n",
       "      <td>0.987593</td>\n",
       "      <td>0.987580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.051118</td>\n",
       "      <td>0.982586</td>\n",
       "      <td>0.982874</td>\n",
       "      <td>0.982586</td>\n",
       "      <td>0.982559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.059224</td>\n",
       "      <td>0.982804</td>\n",
       "      <td>0.983103</td>\n",
       "      <td>0.982804</td>\n",
       "      <td>0.982777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.054300</td>\n",
       "      <td>0.035338</td>\n",
       "      <td>0.990422</td>\n",
       "      <td>0.990494</td>\n",
       "      <td>0.990422</td>\n",
       "      <td>0.990415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.057108</td>\n",
       "      <td>0.986286</td>\n",
       "      <td>0.986498</td>\n",
       "      <td>0.986286</td>\n",
       "      <td>0.986269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.041782</td>\n",
       "      <td>0.990858</td>\n",
       "      <td>0.990930</td>\n",
       "      <td>0.990858</td>\n",
       "      <td>0.990851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.061002</td>\n",
       "      <td>0.987810</td>\n",
       "      <td>0.987968</td>\n",
       "      <td>0.987810</td>\n",
       "      <td>0.987797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.052385</td>\n",
       "      <td>0.983457</td>\n",
       "      <td>0.983791</td>\n",
       "      <td>0.983457</td>\n",
       "      <td>0.983430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>0.033738</td>\n",
       "      <td>0.990640</td>\n",
       "      <td>0.990644</td>\n",
       "      <td>0.990640</td>\n",
       "      <td>0.990641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>0.036805</td>\n",
       "      <td>0.990422</td>\n",
       "      <td>0.990445</td>\n",
       "      <td>0.990422</td>\n",
       "      <td>0.990418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.033725</td>\n",
       "      <td>0.991293</td>\n",
       "      <td>0.991293</td>\n",
       "      <td>0.991293</td>\n",
       "      <td>0.991293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.042695</td>\n",
       "      <td>0.989116</td>\n",
       "      <td>0.989208</td>\n",
       "      <td>0.989116</td>\n",
       "      <td>0.989107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.024285</td>\n",
       "      <td>0.993687</td>\n",
       "      <td>0.993696</td>\n",
       "      <td>0.993687</td>\n",
       "      <td>0.993686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.041941</td>\n",
       "      <td>0.989769</td>\n",
       "      <td>0.989770</td>\n",
       "      <td>0.989769</td>\n",
       "      <td>0.989769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.030976</td>\n",
       "      <td>0.990858</td>\n",
       "      <td>0.990930</td>\n",
       "      <td>0.990858</td>\n",
       "      <td>0.990851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.040073</td>\n",
       "      <td>0.989334</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.989334</td>\n",
       "      <td>0.989335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.031346</td>\n",
       "      <td>0.993470</td>\n",
       "      <td>0.993476</td>\n",
       "      <td>0.993470</td>\n",
       "      <td>0.993468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.039129</td>\n",
       "      <td>0.989987</td>\n",
       "      <td>0.990004</td>\n",
       "      <td>0.989987</td>\n",
       "      <td>0.989983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=TARGET_DIR,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=1000,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    logging_dir=os.path.join(TARGET_DIR, \"logs_other\"),\n",
    "    logging_steps=100,\n",
    "    logging_first_step=True,\n",
    "    warmup_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    # metric_for_best_model=\"f1\",\n",
    "    # greater_is_better=True,\n",
    "    save_total_limit=3,\n",
    "    report_to=[\"tensorboard\"],\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",
    "    data_collator=collate_fn\n",
    ")\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted. Saving the model...\")\n",
    "finally:\n",
    "    model.save_pretrained(os.path.join(TARGET_DIR, \"model_other\"))\n",
    "    processor.save_pretrained(os.path.join(TARGET_DIR, \"processor_other\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea6b8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='457' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [144/144 04:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rest</th>\n",
       "      <th>wit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>0.024456</td>\n",
       "      <td>1.483998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_accuracy</th>\n",
       "      <td>0.993254</td>\n",
       "      <td>0.728400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_precision</th>\n",
       "      <td>0.993265</td>\n",
       "      <td>0.792155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_recall</th>\n",
       "      <td>0.993254</td>\n",
       "      <td>0.728400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_f1</th>\n",
       "      <td>0.993251</td>\n",
       "      <td>0.737035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_runtime</th>\n",
       "      <td>79.925300</td>\n",
       "      <td>169.842100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <td>57.491000</td>\n",
       "      <td>58.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <td>1.802000</td>\n",
       "      <td>1.843000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              rest         wit\n",
       "eval_loss                 0.024456    1.483998\n",
       "eval_accuracy             0.993254    0.728400\n",
       "eval_precision            0.993265    0.792155\n",
       "eval_recall               0.993254    0.728400\n",
       "eval_f1                   0.993251    0.737035\n",
       "eval_runtime             79.925300  169.842100\n",
       "eval_samples_per_second  57.491000   58.878000\n",
       "eval_steps_per_second     1.802000    1.843000\n",
       "epoch                    18.000000   18.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(trainer=trainer).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74088ff3",
   "metadata": {},
   "source": [
    "# Our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46923fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DIR = os.path.join(\n",
    "    CHECKPOINT_DIR, \"siglip2\", \"wit\"\n",
    ")\n",
    "os.makedirs(TARGET_DIR, exist_ok=True)\n",
    "\n",
    "train_ds = ImageFolder(os.path.join(\"datasets\", \"wit_train\"), transform=train_transforms)\n",
    "# train_ds = Subset(train_ds, range(100))\n",
    "val_ds = ImageFolder(os.path.join(\"datasets\", \"wit_val\"), transform=val_transforms)\n",
    "# val_ds = Subset(val_ds, range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53fe5271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12500' max='2500000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  12500/2500000 5:33:02 < 1104:45:02, 0.63 it/s, Epoch 5/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.084800</td>\n",
       "      <td>0.063858</td>\n",
       "      <td>0.976500</td>\n",
       "      <td>0.977085</td>\n",
       "      <td>0.976500</td>\n",
       "      <td>0.976609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.050997</td>\n",
       "      <td>0.981800</td>\n",
       "      <td>0.981802</td>\n",
       "      <td>0.981800</td>\n",
       "      <td>0.981756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.053080</td>\n",
       "      <td>0.982300</td>\n",
       "      <td>0.982316</td>\n",
       "      <td>0.982300</td>\n",
       "      <td>0.982252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.051041</td>\n",
       "      <td>0.981800</td>\n",
       "      <td>0.981844</td>\n",
       "      <td>0.981800</td>\n",
       "      <td>0.981740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.068069</td>\n",
       "      <td>0.973500</td>\n",
       "      <td>0.974930</td>\n",
       "      <td>0.973500</td>\n",
       "      <td>0.973700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=TARGET_DIR,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=1000,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    logging_dir=os.path.join(TARGET_DIR, \"logs_combined\"),\n",
    "    logging_steps=100,\n",
    "    warmup_steps=500,\n",
    "    logging_first_step=True,\n",
    "    load_best_model_at_end=True,\n",
    "    # metric_for_best_model=\"f1\",\n",
    "    # greater_is_better=True,\n",
    "    save_total_limit=3,\n",
    "    report_to=[\"tensorboard\"],\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    data_collator=collate_fn\n",
    ")\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted. Saving the model...\")\n",
    "finally:\n",
    "    model.save_pretrained(os.path.join(TARGET_DIR, \"model_combined\"))\n",
    "    processor.save_pretrained(os.path.join(TARGET_DIR, \"processor_combined\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e237a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='457' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [144/144 04:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rest</th>\n",
       "      <th>wit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>0.461022</td>\n",
       "      <td>0.052640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_accuracy</th>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.982500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_precision</th>\n",
       "      <td>0.903942</td>\n",
       "      <td>0.982496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_recall</th>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.982500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_f1</th>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_runtime</th>\n",
       "      <td>79.085000</td>\n",
       "      <td>168.719600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <td>58.102000</td>\n",
       "      <td>59.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <td>1.821000</td>\n",
       "      <td>1.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              rest         wit\n",
       "eval_loss                 0.461022    0.052640\n",
       "eval_accuracy             0.902067    0.982500\n",
       "eval_precision            0.903942    0.982496\n",
       "eval_recall               0.902067    0.982500\n",
       "eval_f1                   0.901408    0.982456\n",
       "eval_runtime             79.085000  168.719600\n",
       "eval_samples_per_second  58.102000   59.270000\n",
       "eval_steps_per_second     1.821000    1.855000\n",
       "epoch                     5.000000    5.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(trainer=trainer).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
